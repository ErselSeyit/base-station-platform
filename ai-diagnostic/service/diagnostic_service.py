#!/usr/bin/env python3
"""
AI Diagnostic Service

Universal diagnostic service that:
- Accepts problems from ANY communication protocol
- Uses AI to analyze and generate solutions
- Sends solutions back to the device

Supported Protocols:
- TCP/IP Socket (Ethernet)
- Serial/UART (RS-232, RS-485)
- USB Serial
- MQTT (IoT standard)
- HTTP/REST API
- WebSocket (real-time)
- gRPC (high performance)

Supported AI Backends:
- Local Ollama (LLaMA, Mistral)
- Rule-based expert system (offline)
"""

import json
import logging
import threading
import socket
import os
import hmac
import hashlib
from functools import wraps
from abc import ABC, abstractmethod

# OpenTelemetry tracing (optional)
try:
    from opentelemetry import trace
    from opentelemetry.sdk.trace import TracerProvider
    from opentelemetry.sdk.trace.export import BatchSpanProcessor
    from opentelemetry.exporter.zipkin.json import ZipkinExporter
    from opentelemetry.sdk.resources import Resource
    from opentelemetry.instrumentation.flask import FlaskInstrumentor
    OTEL_AVAILABLE = True
except ImportError:
    OTEL_AVAILABLE = False

# Optional serial support
try:
    import serial
    import serial.tools.list_ports
    SERIAL_AVAILABLE = True
except ImportError:
    SERIAL_AVAILABLE = False
from dataclasses import dataclass, asdict, field
from typing import Optional, Dict, Any, List, Callable
from datetime import datetime
from enum import Enum
import queue

# Optional imports for various protocols
try:
    import paho.mqtt.client as mqtt
    MQTT_AVAILABLE = True
except ImportError:
    MQTT_AVAILABLE = False

try:
    from flask import Flask, request, jsonify, Response
    FLASK_AVAILABLE = True
except ImportError:
    FLASK_AVAILABLE = False

# BI Report generation (optional)
try:
    from bi_report_generator import BIReportGenerator
    BI_REPORT_AVAILABLE = True
except ImportError:
    BI_REPORT_AVAILABLE = False

# Computer Vision service (optional)
try:
    from vision_service import get_vision_service, VisionService
    VISION_AVAILABLE = True
except ImportError:
    VISION_AVAILABLE = False

# Alarm Correlation service (optional)
try:
    from alarm_correlation import get_alarm_correlation_service, Alarm
    ALARM_CORRELATION_AVAILABLE = True
except ImportError:
    ALARM_CORRELATION_AVAILABLE = False

# Predictive Maintenance service (optional)
try:
    from predictive_maintenance import get_predictive_maintenance_service, MetricDataPoint
    PREDICTIVE_MAINTENANCE_AVAILABLE = True
except ImportError:
    PREDICTIVE_MAINTENANCE_AVAILABLE = False

# Config Drift Detection service (optional)
try:
    from config_drift_detection import get_config_drift_service
    CONFIG_DRIFT_AVAILABLE = True
except ImportError:
    CONFIG_DRIFT_AVAILABLE = False

try:
    import websockets
    import asyncio
    WEBSOCKET_AVAILABLE = True
except ImportError:
    WEBSOCKET_AVAILABLE = False

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Error messages
LEARNING_ENGINE_NOT_AVAILABLE = "Learning engine not available"


# ============================================================================
# Data Models
# ============================================================================

@dataclass
class Problem:
    """Universal problem format from any device"""
    id: str
    timestamp: str
    station_id: str
    category: str
    severity: str
    code: str
    message: str
    metrics: Dict[str, Any]
    raw_logs: str
    source_protocol: str = "unknown"


@dataclass
class Solution:
    """Solution generated by AI"""
    problem_id: str
    action: str
    commands: List[str]
    expected_outcome: str
    risk_level: str
    confidence: float = 0.0
    reasoning: str = ""


@dataclass
class LearnedPattern:
    """Pattern learned from operator feedback"""
    problem_code: str
    category: str
    resolved_count: int = 0
    failed_count: int = 0
    adjusted_confidence: float = 0.85
    successful_actions: List[str] = field(default_factory=list)
    failed_actions: List[str] = field(default_factory=list)

    def success_rate(self) -> float:
        total = self.resolved_count + self.failed_count
        return (self.resolved_count / total * 100) if total > 0 else 0.0


# ============================================================================
# Learning Engine
# ============================================================================

class LearningEngine:
    """
    Manages learned patterns from operator feedback.
    Adjusts confidence scores based on historical success rates.
    """

    def __init__(self):
        self.patterns: Dict[str, LearnedPattern] = {}
        self._lock = threading.Lock()

    def get_pattern(self, problem_code: str) -> Optional[LearnedPattern]:
        """Get learned pattern for a problem code."""
        with self._lock:
            return self.patterns.get(problem_code)

    def update_pattern(self, problem_code: str, category: str,
                       was_effective: bool, action: str) -> LearnedPattern:
        """Update pattern based on feedback."""
        with self._lock:
            if problem_code not in self.patterns:
                self.patterns[problem_code] = LearnedPattern(
                    problem_code=problem_code,
                    category=category
                )

            pattern = self.patterns[problem_code]

            if was_effective:
                pattern.resolved_count += 1
                if action and action not in pattern.successful_actions:
                    pattern.successful_actions.append(action)
            else:
                pattern.failed_count += 1
                if action and action not in pattern.failed_actions:
                    pattern.failed_actions.append(action)

            # Recalculate confidence based on success rate
            total = pattern.resolved_count + pattern.failed_count
            if total > 0:
                success_rate = pattern.resolved_count / total
                # Weighted average: 30% base + 70% success rate
                pattern.adjusted_confidence = 0.3 * 0.85 + 0.7 * success_rate

            return pattern

    def get_adjusted_confidence(self, problem_code: str,
                                 base_confidence: float) -> float:
        """Get confidence adjusted by learned patterns."""
        pattern = self.get_pattern(problem_code)
        if pattern and (pattern.resolved_count + pattern.failed_count) >= 3:
            # Only use learned confidence if we have enough data
            return pattern.adjusted_confidence
        return base_confidence

    def get_all_patterns(self) -> List[LearnedPattern]:
        """Get all learned patterns."""
        with self._lock:
            return list(self.patterns.values())

    def get_stats(self) -> Dict[str, Any]:
        """Get learning statistics."""
        with self._lock:
            total_resolved = sum(p.resolved_count for p in self.patterns.values())
            total_failed = sum(p.failed_count for p in self.patterns.values())
            total = total_resolved + total_failed

            return {
                "total_patterns": len(self.patterns),
                "total_feedback": total,
                "total_resolved": total_resolved,
                "total_failed": total_failed,
                "overall_success_rate": (total_resolved / total * 100) if total > 0 else 0.0,
                "top_patterns": [
                    {
                        "problem_code": p.problem_code,
                        "success_rate": p.success_rate(),
                        "total_cases": p.resolved_count + p.failed_count,
                        "adjusted_confidence": p.adjusted_confidence
                    }
                    for p in sorted(
                        self.patterns.values(),
                        key=lambda x: x.resolved_count + x.failed_count,
                        reverse=True
                    )[:5]
                ]
            }


# ============================================================================
# AI Backends
# ============================================================================

class AIBackend(ABC):
    """Abstract base class for AI diagnostic backends"""

    @abstractmethod
    def diagnose(self, problem: Problem) -> Solution:
        """Analyze problem and return solution"""
        pass

    @abstractmethod
    def is_available(self) -> bool:
        """Check if backend is available"""
        pass


class RuleBasedBackend(AIBackend):
    """
    Rule-based expert system for offline operation.
    Works without any API keys or internet connection.
    """

    RULES = {
        "CPU_OVERHEAT": {
            "action": "Reduce thermal load and increase cooling",
            "commands": [
                "echo 1 > /sys/class/thermal/cooling_device0/cur_state",
                "systemctl restart fan-controller",
                "cpufreq-set -g powersave",
                "kill -STOP $(pgrep -f non-critical)"
            ],
            "expected_outcome": "CPU temperature should drop below 70C within 5 minutes",
            "risk_level": "low"
        },
        "MEMORY_PRESSURE": {
            "action": "Free memory and restart memory-heavy processes",
            "commands": [
                "sync; echo 3 > /proc/sys/vm/drop_caches",
                "systemctl restart radio_daemon",
                "pkill -9 -f memory_leak_process",
                "swapon -a"
            ],
            "expected_outcome": "Memory usage should drop below 70%",
            "risk_level": "medium"
        },
        "SIGNAL_DEGRADATION": {
            "action": "Optimize antenna and adjust transmission parameters",
            "commands": [
                "radio-cli recalibrate-antenna",
                "radio-cli set-power auto",
                "radio-cli scan-interference",
                "systemctl restart radio_controller"
            ],
            "expected_outcome": "Signal strength should improve by 10-15 dBm",
            "risk_level": "low"
        },
        "BACKHAUL_LATENCY": {
            "action": "Optimize network path and reduce traffic",
            "commands": [
                "tc qdisc replace dev eth0 root fq_codel",
                "ip route flush cache",
                "systemctl restart network-optimizer",
                "ethtool -s eth0 speed 1000 duplex full"
            ],
            "expected_outcome": "Latency should drop below 50ms",
            "risk_level": "low"
        },
        "PROCESS_CRASH": {
            "action": "Restart crashed process and enable core dumps for analysis",
            "commands": [
                "ulimit -c unlimited",
                "systemctl restart radio_controller",
                "journalctl -u radio_controller --since '5 min ago' > /var/log/crash_analysis.log",
                "coredumpctl gdb radio_controller"
            ],
            "expected_outcome": "Process should restart and remain stable",
            "risk_level": "medium"
        },
        "CONFIG_MISMATCH": {
            "action": "Restore configuration from backup and validate",
            "commands": [
                "cp /etc/basestation/radio.conf.backup /etc/basestation/radio.conf",
                "config-validator --check /etc/basestation/radio.conf",
                "systemctl reload radio_controller",
                "logger 'Config restored from backup'"
            ],
            "expected_outcome": "Configuration should be valid and applied",
            "risk_level": "low"
        },
        "POWER_FLUCTUATION": {
            "action": "Activate power protection and reduce load",
            "commands": [
                "power-manager --enable-protection",
                "cpufreq-set -g powersave",
                "radio-cli reduce-power 20",
                "ups-cli --check-battery"
            ],
            "expected_outcome": "System should switch to UPS if needed, power stabilized",
            "risk_level": "high"
        },
        "HIGH_POWER_CONSUMPTION": {
            "action": "Reduce power consumption through efficiency optimization",
            "commands": [
                "radio-cli set-power-mode eco",
                "cpufreq-set -u 1.5GHz",
                "systemctl stop non-essential.target",
                "power-manager --optimize"
            ],
            "expected_outcome": "Power consumption should drop below rated capacity",
            "risk_level": "low"
        },
        "AUTH_FAILURE": {
            "action": "Lock suspicious source and strengthen security",
            "commands": [
                "iptables -A INPUT -s 192.168.1.100 -j DROP",
                "fail2ban-client set sshd banip 192.168.1.100",
                "passwd -l admin",
                "logger -p auth.warning 'Brute force attack detected'"
            ],
            "expected_outcome": "Attack source blocked, accounts secured",
            "risk_level": "low"
        },
        "CERT_EXPIRING": {
            "action": "Renew TLS certificate",
            "commands": [
                "certbot renew --force-renewal",
                "systemctl reload nginx",
                "openssl x509 -in /etc/ssl/certs/server.crt -noout -dates",
                "logger 'Certificate renewed'"
            ],
            "expected_outcome": "Certificate renewed with new expiry date",
            "risk_level": "low"
        },
        # 5G NR Specific Rules (based on Huawei SSV criteria)
        "TX_IMBALANCE_HIGH": {
            "action": "Investigate RF path imbalance and recalibrate antenna system",
            "commands": [
                "radio-cli check-tx-path --all-sectors",
                "radio-cli measure-vswr --threshold 1.5",
                "radio-cli calibrate-rf-chain",
                "radio-cli verify-antenna-connections",
                "logger -p local0.alert 'TX imbalance exceeded 4dB threshold - SSV FAIL'"
            ],
            "expected_outcome": "TX imbalance should drop below 4dB threshold (SSV pass criteria)",
            "risk_level": "high"
        },
        "DL_THROUGHPUT_LOW_NR3500": {
            "action": "Optimize NR3500 downlink performance",
            "commands": [
                "radio-cli check-interference --band NR3500",
                "radio-cli optimize-mcs --target 26",
                "radio-cli adjust-power --band NR3500 --mode auto",
                "radio-cli verify-backhaul-capacity",
                "logger 'NR3500 DL throughput below 1000 Mbps KPI threshold'"
            ],
            "expected_outcome": "DL throughput should reach >= 1000 Mbps (NR3500 100MHz RANK4 256QAM)",
            "risk_level": "medium"
        },
        "UL_THROUGHPUT_LOW_NR3500": {
            "action": "Optimize NR3500 uplink performance",
            "commands": [
                "radio-cli check-ul-interference --band NR3500",
                "radio-cli optimize-ul-grant",
                "radio-cli adjust-ul-power --band NR3500",
                "radio-cli verify-ul-sync",
                "logger 'NR3500 UL throughput below 75 Mbps KPI threshold'"
            ],
            "expected_outcome": "UL throughput should reach >= 75 Mbps (NR3500 100MHz RANK1 256QAM)",
            "risk_level": "medium"
        },
        "DL_THROUGHPUT_LOW_NR700": {
            "action": "Optimize NR700 coverage layer performance",
            "commands": [
                "radio-cli check-interference --band NR700",
                "radio-cli optimize-coverage-layer",
                "radio-cli adjust-power --band NR700 --mode coverage",
                "logger 'NR700 DL throughput below 50 Mbps KPI threshold'"
            ],
            "expected_outcome": "DL throughput should reach >= 50 Mbps (NR700 10MHz RANK2 256QAM)",
            "risk_level": "low"
        },
        "LATENCY_HIGH": {
            "action": "Reduce 5G air interface and backhaul latency",
            "commands": [
                "radio-cli optimize-scheduling --low-latency",
                "radio-cli check-harq-timing",
                "tc qdisc replace dev eth0 root fq_codel target 5ms",
                "radio-cli verify-fronthaul-latency",
                "logger 'Latency exceeded 15ms 5G target'"
            ],
            "expected_outcome": "Latency should drop below 15ms (5G target)",
            "risk_level": "medium"
        },
        "SINR_DEGRADATION": {
            "action": "Improve signal-to-interference ratio",
            "commands": [
                "radio-cli scan-interference --detailed",
                "radio-cli optimize-beamforming",
                "radio-cli adjust-tilt --optimize-sinr",
                "radio-cli check-pci-collision",
                "logger 'SINR below 10dB - coverage degradation detected'"
            ],
            "expected_outcome": "SINR should improve above 15dB for good coverage",
            "risk_level": "medium"
        },
        "HANDOVER_FAILURE": {
            "action": "Investigate and fix inter-cell handover issues",
            "commands": [
                "radio-cli check-neighbor-relations",
                "radio-cli verify-x2-connectivity",
                "radio-cli analyze-handover-logs --last 100",
                "radio-cli optimize-handover-params",
                "logger -p local0.alert 'Handover success rate below 100% - SSV FAIL'"
            ],
            "expected_outcome": "Handover success rate should reach 100% (SSV criteria)",
            "risk_level": "high"
        },
        "RSRP_WEAK": {
            "action": "Improve reference signal coverage",
            "commands": [
                "radio-cli increase-rs-power",
                "radio-cli optimize-antenna-tilt",
                "radio-cli check-feeder-loss",
                "radio-cli verify-antenna-gain",
                "logger 'RSRP below -100dBm - weak coverage area'"
            ],
            "expected_outcome": "RSRP should improve above -85dBm for good coverage",
            "risk_level": "low"
        },
        "BLER_HIGH": {
            "action": "Reduce block error rate",
            "commands": [
                "radio-cli analyze-bler-distribution",
                "radio-cli optimize-harq-retx",
                "radio-cli adjust-mcs-table",
                "radio-cli check-timing-advance",
                "logger 'Initial BLER exceeding 10% threshold'"
            ],
            "expected_outcome": "BLER should drop below 10% for stable transmission",
            "risk_level": "medium"
        }
    }

    def diagnose(self, problem: Problem) -> Solution:
        rule = self.RULES.get(problem.code, {
            "action": "Manual investigation required - unknown problem type",
            "commands": [
                f"logger 'Unknown problem: {problem.code}'",
                "dmesg | tail -100 > /var/log/diagnostic.log",
                "systemctl status --all > /var/log/services.log"
            ],
            "expected_outcome": "Logs collected for manual analysis",
            "risk_level": "unknown"
        })

        return Solution(
            problem_id=problem.id,
            action=rule["action"],
            commands=rule["commands"],
            expected_outcome=rule["expected_outcome"],
            risk_level=rule["risk_level"],
            confidence=0.85 if problem.code in self.RULES else 0.3,
            reasoning=f"Rule-based diagnosis for {problem.code}"
        )

    def is_available(self) -> bool:
        return True


class OllamaBackend(AIBackend):
    """Local Ollama backend for offline AI diagnosis"""

    def __init__(self, model: str = "llama3.2", host: str = "http://localhost:11434"):
        self.model = model
        self.host = host

    def diagnose(self, problem: Problem) -> Solution:
        import requests

        prompt = f"""Diagnose this base station problem and provide a solution:

Problem: {problem.code} - {problem.message}
Metrics: {json.dumps(problem.metrics)}
Logs: {problem.raw_logs}

Respond with JSON: {{"action": "...", "commands": [...], "expected_outcome": "...", "risk_level": "low|medium|high"}}"""

        try:
            response = requests.post(
                f"{self.host}/api/generate",
                json={"model": self.model, "prompt": prompt, "stream": False},
                timeout=60
            )

            if response.ok:
                text = response.json().get("response", "")
                data = json.loads(text)
                return Solution(
                    problem_id=problem.id,
                    action=data.get("action", ""),
                    commands=data.get("commands", []),
                    expected_outcome=data.get("expected_outcome", ""),
                    risk_level=data.get("risk_level", "medium"),
                    confidence=0.7,
                    reasoning="Local LLM analysis"
                )
        except Exception as e:
            logger.error(f"Ollama error: {e}")

        return RuleBasedBackend().diagnose(problem)

    def is_available(self) -> bool:
        try:
            import requests
            r = requests.get(f"{self.host}/api/tags", timeout=2)
            return r.ok
        except Exception:
            return False


# ============================================================================
# Protocol Adapters
# ============================================================================

class ProtocolAdapter(ABC):
    """Base class for communication protocol adapters"""

    def __init__(self, on_problem: Optional[Callable[[Problem], Solution]] = None):
        self.on_problem: Optional[Callable[[Problem], Solution]] = on_problem
        self.running = False

    @abstractmethod
    def start(self):
        """Start listening for problems"""
        pass

    @abstractmethod
    def stop(self):
        """Stop listening"""
        pass

    @abstractmethod
    def send_solution(self, solution: Solution, destination: Any):
        """Send solution back to device"""
        pass


class TCPAdapter(ProtocolAdapter):
    """TCP/IP Socket adapter for Ethernet communication"""

    def __init__(self, on_problem: Optional[Callable[[Problem], Solution]] = None, host: str = "0.0.0.0", port: int = 9090):
        super().__init__(on_problem)
        self.host = host
        self.port = port
        self.server = None

    def start(self):
        self.running = True
        self.server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        self.server.bind((self.host, self.port))
        self.server.listen(5)

        logger.info(f"TCP adapter listening on {self.host}:{self.port}")

        def accept_loop():
            while self.running and self.server:
                try:
                    self.server.settimeout(1.0)
                    conn, addr = self.server.accept()
                    threading.Thread(target=self._handle_client, args=(conn, addr)).start()
                except socket.timeout:
                    continue
                except Exception as e:
                    if self.running:
                        logger.error(f"TCP accept error: {e}")

        threading.Thread(target=accept_loop, daemon=True).start()

    def _handle_client(self, conn, addr):
        logger.info(f"TCP connection from {addr}")
        try:
            data = b''
            while True:
                chunk = conn.recv(4096)
                if not chunk:
                    break
                data += chunk
                if b'\n' in data:
                    break

            if data:
                problem_data = json.loads(data.decode().strip())
                problem = Problem(**problem_data, source_protocol="tcp")

                if self.on_problem:
                    solution = self.on_problem(problem)
                    self.send_solution(solution, conn)

        except Exception as e:
            logger.error(f"TCP client error: {e}")
        finally:
            conn.close()

    def send_solution(self, solution: Solution, conn: socket.socket):
        try:
            response = json.dumps(asdict(solution)) + '\n'
            conn.sendall(response.encode())
        except Exception as e:
            logger.error(f"Failed to send solution: {e}")

    def stop(self):
        self.running = False
        if self.server:
            self.server.close()


class SerialAdapter(ProtocolAdapter):
    """Serial/UART adapter for RS-232, RS-485, USB Serial"""

    def __init__(self, on_problem: Optional[Callable[[Problem], Solution]] = None, port: str = "/dev/ttyUSB0",
                 baudrate: int = 115200, timeout: float = 1.0):
        super().__init__(on_problem)
        self.port = port
        self.baudrate = baudrate
        self.timeout = timeout
        self.serial_conn = None

    @staticmethod
    def list_ports() -> List[str]:
        """List available serial ports"""
        if not SERIAL_AVAILABLE:
            return []
        ports = serial.tools.list_ports.comports()
        return [p.device for p in ports]

    def _read_loop(self):
        """Read serial data in a loop and process complete lines."""
        buffer = ""
        while self.running and self.serial_conn:
            try:
                if self.serial_conn.in_waiting:
                    data = self.serial_conn.read(self.serial_conn.in_waiting).decode()
                    buffer = self._process_buffer(buffer + data)
            except Exception as e:
                logger.error(f"Serial read error: {e}")

    def _process_buffer(self, buffer: str) -> str:
        """Process buffer, handling complete lines and returning remainder."""
        while '\n' in buffer:
            line, buffer = buffer.split('\n', 1)
            if line.strip():
                self._process_message(line.strip())
        return buffer

    def start(self):
        if not SERIAL_AVAILABLE:
            logger.warning("Serial not available - install pyserial")
            return

        self.running = True
        try:
            self.serial_conn = serial.Serial(
                port=self.port,
                baudrate=self.baudrate,
                timeout=self.timeout
            )
            logger.info(f"Serial adapter connected to {self.port} at {self.baudrate} baud")
            threading.Thread(target=self._read_loop, daemon=True).start()

        except serial.SerialException as e:
            logger.error(f"Failed to open serial port {self.port}: {e}")
            logger.info(f"Available ports: {self.list_ports()}")

    def _process_message(self, message: str):
        try:
            problem_data = json.loads(message)
            problem = Problem(**problem_data, source_protocol="serial")
            if self.on_problem:
                solution = self.on_problem(problem)
                self.send_solution(solution, None)
        except json.JSONDecodeError:
            logger.warning(f"Invalid JSON from serial: {message[:100]}")

    def send_solution(self, solution: Solution, _):
        if self.serial_conn and self.serial_conn.is_open:
            response = json.dumps(asdict(solution)) + '\n'
            self.serial_conn.write(response.encode())

    def stop(self):
        self.running = False
        if self.serial_conn:
            self.serial_conn.close()


class MQTTAdapter(ProtocolAdapter):
    """MQTT adapter for IoT communication"""

    def __init__(self, on_problem: Optional[Callable[[Problem], Solution]] = None, broker: str = "localhost", port: int = 1883,
                 topic_problems: str = "basestation/+/problems",
                 topic_solutions: str = "basestation/{station_id}/solutions"):
        super().__init__(on_problem)
        self.broker = broker
        self.port = port
        self.topic_problems = topic_problems
        self.topic_solutions = topic_solutions
        self.client = None

    def start(self):
        if not MQTT_AVAILABLE:
            logger.warning("MQTT not available - install paho-mqtt")
            return

        self.running = True
        self.client = mqtt.Client()

        def on_connect(client, userdata, flags, rc):
            logger.info(f"MQTT connected to {self.broker}:{self.port}")
            client.subscribe(self.topic_problems)

        def on_message(client, userdata, msg):
            try:
                problem_data = json.loads(msg.payload.decode())
                problem = Problem(**problem_data, source_protocol="mqtt")
                if self.on_problem:
                    solution = self.on_problem(problem)
                    self.send_solution(solution, problem.station_id)
            except Exception as e:
                logger.error(f"MQTT message error: {e}")

        self.client.on_connect = on_connect
        self.client.on_message = on_message

        try:
            self.client.connect(self.broker, self.port)
            self.client.loop_start()
        except Exception as e:
            logger.error(f"MQTT connection failed: {e}")

    def send_solution(self, solution: Solution, station_id: str):
        if self.client:
            topic = self.topic_solutions.format(station_id=station_id)
            self.client.publish(topic, json.dumps(asdict(solution)))

    def stop(self):
        self.running = False
        if self.client:
            self.client.loop_stop()
            self.client.disconnect()


class HTTPAdapter(ProtocolAdapter):
    """HTTP/REST API adapter with HMAC authentication and OpenTelemetry tracing"""

    def __init__(self, on_problem: Optional[Callable[[Problem], Solution]] = None, host: str = "0.0.0.0", port: int = 9091):
        super().__init__(on_problem)
        self.host = host
        self.port = port
        self.app: Optional["Flask"] = None
        self.secret = os.environ.get("DIAGNOSTIC_SECRET", "")
        self.tracer = None
        # References to diagnostic logs and learning engine (set by DiagnosticService)
        self.problem_log: List[Problem] = []
        self.solution_log: List[Solution] = []
        self.learning_engine: Optional[LearningEngine] = None
        self.diagnostic_service: Optional["DiagnosticService"] = None  # Reference to parent service
        require_auth = os.environ.get("DIAGNOSTIC_REQUIRE_AUTH", "false").lower() == "true"
        if not self.secret:
            if require_auth:
                raise ValueError("DIAGNOSTIC_SECRET is required when DIAGNOSTIC_REQUIRE_AUTH=true")
            logger.warning("DIAGNOSTIC_SECRET not set - authentication disabled (set DIAGNOSTIC_REQUIRE_AUTH=true in production)")

    def _setup_tracing(self):
        """Initialize OpenTelemetry tracing"""
        if not OTEL_AVAILABLE:
            logger.info("OpenTelemetry not available - tracing disabled")
            return

        zipkin_endpoint = os.environ.get("ZIPKIN_ENDPOINT", "http://zipkin:9411/api/v2/spans")

        try:
            resource = Resource.create({"service.name": "ai-diagnostic"})
            provider = TracerProvider(resource=resource)
            exporter = ZipkinExporter(endpoint=zipkin_endpoint)
            provider.add_span_processor(BatchSpanProcessor(exporter))
            trace.set_tracer_provider(provider)
            self.tracer = trace.get_tracer(__name__)

            # Instrument Flask app
            if self.app:
                FlaskInstrumentor().instrument_app(self.app)

            logger.info(f"OpenTelemetry tracing enabled, exporting to {zipkin_endpoint}")
        except Exception as e:
            logger.warning(f"Failed to initialize tracing: {e}")

    def _verify_hmac(self, body: bytes, signature: str) -> bool:
        """Verify HMAC signature of request body"""
        if not self.secret:
            return True  # Auth disabled if no secret configured

        expected = hmac.new(
            self.secret.encode(),
            body,
            hashlib.sha256
        ).hexdigest()

        return hmac.compare_digest(expected, signature)

    def _require_auth(self, f):
        """Decorator to require HMAC authentication"""
        @wraps(f)
        def decorated(*args, **kwargs):
            if not self.secret:
                return f(*args, **kwargs)

            signature = request.headers.get("X-HMAC-Signature", "")
            if not signature:
                logger.warning("Missing X-HMAC-Signature header")
                return jsonify({"error": "Missing authentication"}), 401

            if not self._verify_hmac(request.get_data(), signature):
                logger.warning("Invalid HMAC signature from %s", request.remote_addr)
                return jsonify({"error": "Invalid authentication"}), 403

            return f(*args, **kwargs)
        return decorated

    def _handle_diagnose(self):
        """Handle POST /diagnose request."""
        if not self.on_problem:
            return jsonify({"error": "Diagnostic handler not configured"}), 503
        problem_data = request.json
        problem = Problem(**problem_data, source_protocol="http")
        solution = self.on_problem(problem)
        return jsonify(asdict(solution))

    def _handle_health(self):
        """Handle GET /health request."""
        return jsonify({
            "status": "ok",
            "authenticated": bool(self.secret),
            "tracing": OTEL_AVAILABLE and self.tracer is not None
        })

    def _handle_bi_report(self):
        """Handle GET /reports/bi request."""
        if not BI_REPORT_AVAILABLE:
            return jsonify({"error": "BI report generation not available"}), 503

        api_url = os.environ.get("API_GATEWAY_URL", "http://localhost:8080")
        generator = BIReportGenerator(api_url)
        pdf_bytes = generator.generate_report_bytes()

        if pdf_bytes is None:
            return jsonify({"error": "Failed to generate report"}), 500

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"bi-report-{timestamp}.pdf"

        return Response(
            pdf_bytes,
            mimetype='application/pdf',
            headers={
                'Content-Disposition': f'attachment; filename="{filename}"',
                'Content-Length': str(len(pdf_bytes))
            }
        )

    def _build_diagnostic_entry(self, index: int, problem: Problem) -> dict:
        """Build a diagnostic entry with optional solution."""
        entry = {
            "id": problem.id,
            "timestamp": problem.timestamp,
            "station_id": problem.station_id,
            "category": problem.category,
            "severity": problem.severity,
            "code": problem.code,
            "message": problem.message,
            "source_protocol": problem.source_protocol,
            "solution": None
        }
        if index < len(self.solution_log):
            sol = self.solution_log[index]
            entry["solution"] = {
                "action": sol.action,
                "commands": sol.commands,
                "expected_outcome": sol.expected_outcome,
                "risk_level": sol.risk_level,
                "confidence": sol.confidence,
                "reasoning": sol.reasoning
            }
        return entry

    def _handle_diagnostics_log(self):
        """Handle GET /reports/diagnostics request."""
        diagnostics = [
            self._build_diagnostic_entry(i, problem)
            for i, problem in enumerate(self.problem_log)
        ]
        return jsonify({"total": len(diagnostics), "diagnostics": diagnostics})

    def _handle_feedback(self):
        """Handle POST /learning/feedback request."""
        if not self.diagnostic_service:
            return jsonify({"error": LEARNING_ENGINE_NOT_AVAILABLE}), 503

        data = request.json
        problem_code = data.get('problem_code')
        if not problem_code:
            return jsonify({"error": "problem_code is required"}), 400

        pattern = self.diagnostic_service.record_feedback(
            problem_code,
            data.get('category', 'unknown'),
            data.get('was_effective', False),
            data.get('action', '')
        )

        return jsonify({
            "problem_code": pattern.problem_code,
            "success_rate": pattern.success_rate(),
            "resolved_count": pattern.resolved_count,
            "failed_count": pattern.failed_count,
            "adjusted_confidence": pattern.adjusted_confidence
        })

    @staticmethod
    def _serialize_pattern(pattern) -> dict:
        """Serialize a learning pattern to dict."""
        return {
            "problem_code": pattern.problem_code,
            "category": pattern.category,
            "resolved_count": pattern.resolved_count,
            "failed_count": pattern.failed_count,
            "success_rate": pattern.success_rate(),
            "adjusted_confidence": pattern.adjusted_confidence,
            "successful_actions": pattern.successful_actions,
            "failed_actions": pattern.failed_actions
        }

    def _handle_learning_stats(self):
        """Handle GET /learning/stats request."""
        if not self.learning_engine:
            return jsonify({"error": LEARNING_ENGINE_NOT_AVAILABLE}), 503
        return jsonify(self.learning_engine.get_stats())

    def _handle_patterns(self):
        """Handle GET /learning/patterns request."""
        if not self.learning_engine:
            return jsonify({"error": LEARNING_ENGINE_NOT_AVAILABLE}), 503

        patterns = self.learning_engine.get_all_patterns()
        return jsonify({
            "total": len(patterns),
            "patterns": [self._serialize_pattern(p) for p in patterns]
        })

    def _handle_pattern(self, problem_code: str):
        """Handle GET /learning/patterns/<problem_code> request."""
        if not self.learning_engine:
            return jsonify({"error": LEARNING_ENGINE_NOT_AVAILABLE}), 503

        pattern = self.learning_engine.get_pattern(problem_code)
        if not pattern:
            return jsonify({"error": "Pattern not found"}), 404

        return jsonify(self._serialize_pattern(pattern))

    # =========================================================================
    # Computer Vision Endpoints
    # =========================================================================

    def _handle_vision_analyze_led(self):
        """Handle POST /vision/analyze-led request.

        Accepts either:
        - JSON with base64_image field
        - multipart/form-data with image file
        """
        if not VISION_AVAILABLE:
            return jsonify({"error": "Vision service not available - install opencv-python-headless"}), 503

        vision_service = get_vision_service()

        try:
            if request.content_type and 'multipart/form-data' in request.content_type:
                # Handle file upload
                if 'image' not in request.files:
                    return jsonify({"error": "No image file provided"}), 400
                file = request.files['image']
                image_data = file.read()
                station_id = request.form.get('station_id', 'unknown')
                expected_leds = int(request.form.get('expected_leds', 0))
            else:
                # Handle JSON with base64
                data = request.json
                if not data or 'base64_image' not in data:
                    return jsonify({"error": "base64_image field is required"}), 400
                station_id = data.get('station_id', 'unknown')
                expected_leds = data.get('expected_leds', 0)
                result = vision_service.analyze_from_base64(
                    data['base64_image'], station_id, expected_leds
                )
                return jsonify(vision_service.to_dict(result))

            result = vision_service.analyze_led_panel(image_data, station_id, expected_leds)
            return jsonify(vision_service.to_dict(result))

        except ValueError as e:
            return jsonify({"error": str(e)}), 400
        except Exception as e:
            logger.error(f"Vision analysis error: {e}")
            return jsonify({"error": f"Analysis failed: {str(e)}"}), 500

    # =========================================================================
    # Alarm Correlation Endpoints
    # =========================================================================

    def _handle_alarms_correlate(self):
        """Handle POST /alarms/correlate request.

        Body: {"alarms": [{"alarm_id": "...", "station_id": "...", ...}, ...]}
        """
        if not ALARM_CORRELATION_AVAILABLE:
            return jsonify({"error": "Alarm correlation service not available - install scikit-learn"}), 503

        correlation_service = get_alarm_correlation_service()

        try:
            data = request.json
            if not data or 'alarms' not in data:
                return jsonify({"error": "alarms field is required"}), 400

            # Convert JSON to Alarm objects
            from alarm_correlation import AlarmSeverity
            alarms = []
            for alarm_data in data['alarms']:
                # Map severity string to enum
                severity_str = alarm_data['severity'].upper()
                try:
                    severity = AlarmSeverity[severity_str]
                except KeyError:
                    severity = AlarmSeverity.WARNING

                alarm = Alarm(
                    alarm_id=alarm_data['alarm_id'],
                    station_id=alarm_data['station_id'],
                    timestamp=datetime.fromisoformat(alarm_data['timestamp']),
                    alarm_type=alarm_data['alarm_type'],
                    severity=severity,
                    message=alarm_data.get('message', ''),
                    metric_type=alarm_data.get('metric_type'),
                    metric_value=alarm_data.get('metric_value')
                )
                alarms.append(alarm)

            # Run correlation analysis
            result = correlation_service.correlate_alarms(alarms)

            return jsonify(result.to_dict())

        except KeyError as e:
            return jsonify({"error": f"Missing required field: {e}"}), 400
        except Exception as e:
            logger.error(f"Alarm correlation error: {e}")
            return jsonify({"error": f"Correlation failed: {str(e)}"}), 500

    # =========================================================================
    # Predictive Maintenance Endpoints
    # =========================================================================

    def _handle_maintenance_health(self, station_id: str):
        """Handle GET /maintenance/<station_id>/health request."""
        if not PREDICTIVE_MAINTENANCE_AVAILABLE:
            return jsonify({"error": "Predictive maintenance service not available - install scikit-learn"}), 503

        maintenance_service = get_predictive_maintenance_service()

        try:
            # Get metric data from query params or use defaults
            include_recommendations = request.args.get('include_recommendations', 'true').lower() == 'true'

            report = maintenance_service.get_station_health_report(station_id)
            result = report  # Already a dict

            if not include_recommendations:
                result.pop('recommendations', None)

            return jsonify(result)

        except Exception as e:
            logger.error(f"Maintenance health report error: {e}")
            return jsonify({"error": f"Health report failed: {str(e)}"}), 500

    def _handle_maintenance_analyze(self):
        """Handle POST /maintenance/analyze request.

        Body: {
            "station_id": "BS-001",
            "metrics": [
                {"metric_type": "FAN_SPEED", "value": 2500, "timestamp": "..."},
                ...
            ]
        }
        """
        if not PREDICTIVE_MAINTENANCE_AVAILABLE:
            return jsonify({"error": "Predictive maintenance service not available"}), 503

        maintenance_service = get_predictive_maintenance_service()

        try:
            data = request.json
            if not data:
                return jsonify({"error": "Request body is required"}), 400

            station_id = data.get('station_id', 'unknown')
            metrics_data = data.get('metrics', [])

            # Convert to MetricDataPoint objects and add to service
            for m in metrics_data:
                point = MetricDataPoint(
                    timestamp=datetime.fromisoformat(m['timestamp']),
                    metric_type=m['metric_type'],
                    value=m['value'],
                    station_id=station_id
                )
                maintenance_service.add_metric(point)

            # Generate health report (already returns dict)
            report = maintenance_service.get_station_health_report(station_id)
            return jsonify(report)

        except KeyError as e:
            return jsonify({"error": f"Missing required field: {e}"}), 400
        except Exception as e:
            logger.error(f"Maintenance analysis error: {e}")
            return jsonify({"error": f"Analysis failed: {str(e)}"}), 500

    # =========================================================================
    # Configuration Drift Detection Endpoints
    # =========================================================================

    def _handle_config_drift_detect(self):
        """Handle POST /config/drift request.

        Body: {
            "station_id": "BS-001",
            "current_config": {"param1": "value1", ...},
            "baseline_config": {"param1": "baseline1", ...}  # optional
        }
        """
        if not CONFIG_DRIFT_AVAILABLE:
            return jsonify({"error": "Config drift detection service not available"}), 503

        drift_service = get_config_drift_service()

        try:
            data = request.json
            if not data:
                return jsonify({"error": "Request body is required"}), 400

            station_id = data.get('station_id', 'unknown')
            current_config = data.get('current_config')

            if not current_config:
                return jsonify({"error": "current_config is required"}), 400

            # Set baseline if provided
            baseline_config = data.get('baseline_config')
            if baseline_config:
                drift_service.set_baseline(station_id, baseline_config)

            # Detect drift
            report = drift_service.detect_drift(station_id, current_config)

            if report is None:
                return jsonify({
                    "error": "No baseline configuration found for station",
                    "hint": "Provide baseline_config in the request or call /config/baseline first"
                }), 400

            return jsonify(report.to_dict())

        except Exception as e:
            logger.error(f"Config drift detection error: {e}")
            return jsonify({"error": f"Drift detection failed: {str(e)}"}), 500

    def _handle_config_baseline_set(self):
        """Handle POST /config/baseline request.

        Body: {
            "station_id": "BS-001",
            "config": {"param1": "value1", ...}
        }
        """
        if not CONFIG_DRIFT_AVAILABLE:
            return jsonify({"error": "Config drift detection service not available"}), 503

        drift_service = get_config_drift_service()

        try:
            data = request.json
            if not data:
                return jsonify({"error": "Request body is required"}), 400

            station_id = data.get('station_id')
            config = data.get('config')

            if not station_id:
                return jsonify({"error": "station_id is required"}), 400
            if not config:
                return jsonify({"error": "config is required"}), 400

            drift_service.set_baseline(station_id, config)

            return jsonify({
                "status": "ok",
                "station_id": station_id,
                "parameters_count": len(config),
                "message": "Baseline configuration saved"
            })

        except Exception as e:
            logger.error(f"Config baseline set error: {e}")
            return jsonify({"error": f"Failed to set baseline: {str(e)}"}), 500

    def _handle_config_baseline_get(self, station_id: str):
        """Handle GET /config/baseline/<station_id> request."""
        if not CONFIG_DRIFT_AVAILABLE:
            return jsonify({"error": "Config drift detection service not available"}), 503

        drift_service = get_config_drift_service()

        baseline = drift_service.get_baseline(station_id)
        if baseline is None:
            return jsonify({"error": "No baseline found for station"}), 404

        return jsonify({
            "station_id": station_id,
            "baseline": baseline
        })

    def _add_cors_headers(self, response):
        """Add CORS headers to response."""
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'GET, POST, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type, X-HMAC-Signature'
        return response

    def _register_routes(self):
        """Register all Flask routes."""
        assert self.app is not None, "Flask app must be initialized before registering routes"
        app = self.app  # Local reference for type narrowing

        app.after_request(self._add_cors_headers)

        app.route('/diagnose', methods=['POST'])(
            self._require_auth(self._handle_diagnose))
        app.route('/health', methods=['GET'])(self._handle_health)
        app.route('/reports/bi', methods=['GET'])(self._handle_bi_report)
        app.route('/reports/diagnostics', methods=['GET'])(self._handle_diagnostics_log)
        app.route('/learning/feedback', methods=['POST'])(
            self._require_auth(self._handle_feedback))
        app.route('/learning/stats', methods=['GET'])(self._handle_learning_stats)
        app.route('/learning/patterns', methods=['GET'])(self._handle_patterns)
        app.route('/learning/patterns/<problem_code>', methods=['GET'])(self._handle_pattern)

        # Computer Vision endpoints
        app.route('/vision/analyze-led', methods=['POST'])(
            self._require_auth(self._handle_vision_analyze_led))

        # Alarm Correlation endpoints
        app.route('/alarms/correlate', methods=['POST'])(
            self._require_auth(self._handle_alarms_correlate))

        # Predictive Maintenance endpoints
        app.route('/maintenance/<station_id>/health', methods=['GET'])(
            self._handle_maintenance_health)
        app.route('/maintenance/analyze', methods=['POST'])(
            self._require_auth(self._handle_maintenance_analyze))

        # Configuration Drift Detection endpoints
        app.route('/config/drift', methods=['POST'])(
            self._require_auth(self._handle_config_drift_detect))
        app.route('/config/baseline', methods=['POST'])(
            self._require_auth(self._handle_config_baseline_set))
        app.route('/config/baseline/<station_id>', methods=['GET'])(
            self._handle_config_baseline_get)

    def start(self):
        if not FLASK_AVAILABLE:
            logger.warning("Flask not available - install flask")
            return

        self.running = True
        self.app = Flask(__name__)
        self._setup_tracing()
        self._register_routes()

        app = self.app
        assert app is not None  # Type narrowing for lambda
        threading.Thread(
            target=lambda: app.run(host=self.host, port=self.port, threaded=True),
            daemon=True
        ).start()

        logger.info(f"HTTP adapter listening on {self.host}:{self.port}")

    def send_solution(self, solution: Solution, _):
        pass  # HTTP is request/response, solution sent in response

    def stop(self):
        self.running = False


# ============================================================================
# Main Diagnostic Service
# ============================================================================

class DiagnosticService:
    """
    Main AI Diagnostic Service

    Manages multiple protocol adapters, AI backends, and the learning engine.
    """

    def __init__(self):
        self.adapters: List[ProtocolAdapter] = []
        self.backend: AIBackend = RuleBasedBackend()
        self.problem_log: List[Problem] = []
        self.solution_log: List[Solution] = []
        self.learning_engine = LearningEngine()

    def set_backend(self, backend: AIBackend):
        """Set the AI backend for diagnosis"""
        self.backend = backend
        logger.info(f"AI backend set to: {type(backend).__name__}")

    def add_adapter(self, adapter: ProtocolAdapter):
        """Add a protocol adapter"""
        self.adapters.append(adapter)
        logger.info(f"Added adapter: {type(adapter).__name__}")

    def record_feedback(self, problem_code: str, category: str,
                        was_effective: bool, action: str) -> LearnedPattern:
        """Record operator feedback and update learning patterns."""
        pattern = self.learning_engine.update_pattern(
            problem_code, category, was_effective, action
        )
        logger.info(f"Feedback recorded for {problem_code}: "
                   f"effective={was_effective}, success_rate={pattern.success_rate():.1f}%")
        return pattern

    def _handle_problem(self, problem: Problem) -> Solution:
        """Central problem handler called by all adapters"""
        logger.info(f"Received problem from {problem.source_protocol}: "
                   f"[{problem.severity}] {problem.code}")

        self.problem_log.append(problem)

        # Diagnose using AI backend
        solution = self.backend.diagnose(problem)

        # Adjust confidence based on learned patterns
        adjusted_confidence = self.learning_engine.get_adjusted_confidence(
            problem.code, solution.confidence
        )
        if adjusted_confidence != solution.confidence:
            logger.info(f"Adjusted confidence for {problem.code}: "
                       f"{solution.confidence:.0%} -> {adjusted_confidence:.0%}")
            solution.confidence = adjusted_confidence

        self.solution_log.append(solution)

        logger.info(f"Generated solution: {solution.action} "
                   f"(confidence: {solution.confidence:.0%})")

        return solution

    def start(self):
        """Start all adapters"""
        logger.info("Starting AI Diagnostic Service")
        logger.info(f"Backend: {type(self.backend).__name__}")
        logger.info(f"Adapters: {len(self.adapters)}")
        logger.info("Learning Engine: enabled")

        for adapter in self.adapters:
            adapter.on_problem = self._handle_problem
            # Share log and learning references with HTTPAdapter
            if isinstance(adapter, HTTPAdapter):
                adapter.problem_log = self.problem_log
                adapter.solution_log = self.solution_log
                adapter.learning_engine = self.learning_engine
                adapter.diagnostic_service = self
            adapter.start()

    def stop(self):
        """Stop all adapters"""
        for adapter in self.adapters:
            adapter.stop()
        logger.info("Diagnostic service stopped")


def main():
    import argparse

    parser = argparse.ArgumentParser(description="AI Diagnostic Service")
    parser.add_argument("--tcp-port", type=int, default=9090, help="TCP port")
    parser.add_argument("--http-port", type=int, default=9091, help="HTTP port")
    parser.add_argument("--serial", help="Serial port (e.g., /dev/ttyUSB0)")
    parser.add_argument("--mqtt-broker", help="MQTT broker address")
    parser.add_argument("--backend", choices=["rules", "ollama"],
                       default="rules", help="AI backend")
    parser.add_argument("--ollama-model", default="llama3.2", help="Ollama model")

    args = parser.parse_args()

    service = DiagnosticService()

    # Set AI backend
    if args.backend == "ollama":
        service.set_backend(OllamaBackend(model=args.ollama_model))
    else:
        service.set_backend(RuleBasedBackend())

    # Add protocol adapters
    service.add_adapter(TCPAdapter(None, port=args.tcp_port))

    if FLASK_AVAILABLE:
        service.add_adapter(HTTPAdapter(None, port=args.http_port))

    if args.serial:
        service.add_adapter(SerialAdapter(None, port=args.serial))

    if args.mqtt_broker and MQTT_AVAILABLE:
        service.add_adapter(MQTTAdapter(None, broker=args.mqtt_broker))

    service.start()

    logger.info("\n" + "="*60)
    logger.info("AI Diagnostic Service is running")
    logger.info("="*60)
    logger.info(f"  TCP:  localhost:{args.tcp_port}")
    if FLASK_AVAILABLE:
        logger.info(f"  HTTP: http://localhost:{args.http_port}")
        logger.info("  Endpoints:")
        logger.info("    POST /diagnose           - AI diagnosis")
        logger.info("    GET  /health             - Health check")
        logger.info("    GET  /reports/bi         - BI report PDF")
        logger.info("    GET  /reports/diagnostics- Diagnostic log")
        if VISION_AVAILABLE:
            logger.info("    POST /vision/analyze-led - LED panel analysis")
        if ALARM_CORRELATION_AVAILABLE:
            logger.info("    POST /alarms/correlate   - Alarm correlation")
        if PREDICTIVE_MAINTENANCE_AVAILABLE:
            logger.info("    GET  /maintenance/{id}/health - Health report")
            logger.info("    POST /maintenance/analyze     - Analyze metrics")
        if CONFIG_DRIFT_AVAILABLE:
            logger.info("    POST /config/drift       - Detect drift")
            logger.info("    POST /config/baseline    - Set baseline")
    if args.serial:
        logger.info(f"  Serial: {args.serial}")
    if args.mqtt_broker:
        logger.info(f"  MQTT: {args.mqtt_broker}")
    logger.info("="*60 + "\n")

    try:
        while True:
            import time
            time.sleep(1)
    except KeyboardInterrupt:
        service.stop()


if __name__ == "__main__":
    main()
