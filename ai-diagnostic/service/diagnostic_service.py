#!/usr/bin/env python3
"""
AI Diagnostic Service

Universal diagnostic service that:
- Accepts problems from ANY communication protocol
- Uses AI to analyze and generate solutions
- Sends solutions back to the device

Supported Protocols:
- TCP/IP Socket (Ethernet)
- Serial/UART (RS-232, RS-485)
- USB Serial
- MQTT (IoT standard)
- HTTP/REST API
- WebSocket (real-time)
- gRPC (high performance)

Supported AI Backends:
- Local Ollama (LLaMA, Mistral)
- Rule-based expert system (offline)
"""

import json
import logging
import threading
import socket
import os
import hmac
import hashlib
from functools import wraps
from abc import ABC, abstractmethod

# OpenTelemetry tracing (optional)
try:
    from opentelemetry import trace
    from opentelemetry.sdk.trace import TracerProvider
    from opentelemetry.sdk.trace.export import BatchSpanProcessor
    from opentelemetry.exporter.zipkin.json import ZipkinExporter
    from opentelemetry.sdk.resources import Resource
    from opentelemetry.instrumentation.flask import FlaskInstrumentor
    OTEL_AVAILABLE = True
except ImportError:
    OTEL_AVAILABLE = False

# Optional serial support
try:
    import serial
    import serial.tools.list_ports
    SERIAL_AVAILABLE = True
except ImportError:
    SERIAL_AVAILABLE = False
from dataclasses import dataclass, asdict
from typing import Optional, Dict, Any, List, Callable
from datetime import datetime
from enum import Enum
import queue

# Optional imports for various protocols
try:
    import paho.mqtt.client as mqtt
    MQTT_AVAILABLE = True
except ImportError:
    MQTT_AVAILABLE = False

try:
    from flask import Flask, request, jsonify, Response
    FLASK_AVAILABLE = True
except ImportError:
    FLASK_AVAILABLE = False

# BI Report generation (optional)
try:
    from bi_report_generator import BIReportGenerator
    BI_REPORT_AVAILABLE = True
except ImportError:
    BI_REPORT_AVAILABLE = False

try:
    import websockets
    import asyncio
    WEBSOCKET_AVAILABLE = True
except ImportError:
    WEBSOCKET_AVAILABLE = False

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Error messages
LEARNING_ENGINE_NOT_AVAILABLE = "Learning engine not available"


# ============================================================================
# Data Models
# ============================================================================

@dataclass
class Problem:
    """Universal problem format from any device"""
    id: str
    timestamp: str
    station_id: str
    category: str
    severity: str
    code: str
    message: str
    metrics: Dict[str, Any]
    raw_logs: str
    source_protocol: str = "unknown"


@dataclass
class Solution:
    """Solution generated by AI"""
    problem_id: str
    action: str
    commands: List[str]
    expected_outcome: str
    risk_level: str
    confidence: float = 0.0
    reasoning: str = ""


@dataclass
class LearnedPattern:
    """Pattern learned from operator feedback"""
    problem_code: str
    category: str
    resolved_count: int = 0
    failed_count: int = 0
    adjusted_confidence: float = 0.85
    successful_actions: Optional[List[str]] = None
    failed_actions: Optional[List[str]] = None

    def __post_init__(self):
        if self.successful_actions is None:
            self.successful_actions = []
        if self.failed_actions is None:
            self.failed_actions = []

    def success_rate(self) -> float:
        total = self.resolved_count + self.failed_count
        return (self.resolved_count / total * 100) if total > 0 else 0.0


# ============================================================================
# Learning Engine
# ============================================================================

class LearningEngine:
    """
    Manages learned patterns from operator feedback.
    Adjusts confidence scores based on historical success rates.
    """

    def __init__(self):
        self.patterns: Dict[str, LearnedPattern] = {}
        self._lock = threading.Lock()

    def get_pattern(self, problem_code: str) -> Optional[LearnedPattern]:
        """Get learned pattern for a problem code."""
        with self._lock:
            return self.patterns.get(problem_code)

    def update_pattern(self, problem_code: str, category: str,
                       was_effective: bool, action: str) -> LearnedPattern:
        """Update pattern based on feedback."""
        with self._lock:
            if problem_code not in self.patterns:
                self.patterns[problem_code] = LearnedPattern(
                    problem_code=problem_code,
                    category=category
                )

            pattern = self.patterns[problem_code]

            if was_effective:
                pattern.resolved_count += 1
                if action and action not in pattern.successful_actions:
                    pattern.successful_actions.append(action)
            else:
                pattern.failed_count += 1
                if action and action not in pattern.failed_actions:
                    pattern.failed_actions.append(action)

            # Recalculate confidence based on success rate
            total = pattern.resolved_count + pattern.failed_count
            if total > 0:
                success_rate = pattern.resolved_count / total
                # Weighted average: 30% base + 70% success rate
                pattern.adjusted_confidence = 0.3 * 0.85 + 0.7 * success_rate

            return pattern

    def get_adjusted_confidence(self, problem_code: str,
                                 base_confidence: float) -> float:
        """Get confidence adjusted by learned patterns."""
        pattern = self.get_pattern(problem_code)
        if pattern and (pattern.resolved_count + pattern.failed_count) >= 3:
            # Only use learned confidence if we have enough data
            return pattern.adjusted_confidence
        return base_confidence

    def get_all_patterns(self) -> List[LearnedPattern]:
        """Get all learned patterns."""
        with self._lock:
            return list(self.patterns.values())

    def get_stats(self) -> Dict[str, Any]:
        """Get learning statistics."""
        with self._lock:
            total_resolved = sum(p.resolved_count for p in self.patterns.values())
            total_failed = sum(p.failed_count for p in self.patterns.values())
            total = total_resolved + total_failed

            return {
                "total_patterns": len(self.patterns),
                "total_feedback": total,
                "total_resolved": total_resolved,
                "total_failed": total_failed,
                "overall_success_rate": (total_resolved / total * 100) if total > 0 else 0.0,
                "top_patterns": [
                    {
                        "problem_code": p.problem_code,
                        "success_rate": p.success_rate(),
                        "total_cases": p.resolved_count + p.failed_count,
                        "adjusted_confidence": p.adjusted_confidence
                    }
                    for p in sorted(
                        self.patterns.values(),
                        key=lambda x: x.resolved_count + x.failed_count,
                        reverse=True
                    )[:5]
                ]
            }


# ============================================================================
# AI Backends
# ============================================================================

class AIBackend(ABC):
    """Abstract base class for AI diagnostic backends"""

    @abstractmethod
    def diagnose(self, problem: Problem) -> Solution:
        """Analyze problem and return solution"""
        pass

    @abstractmethod
    def is_available(self) -> bool:
        """Check if backend is available"""
        pass


class RuleBasedBackend(AIBackend):
    """
    Rule-based expert system for offline operation.
    Works without any API keys or internet connection.
    """

    RULES = {
        "CPU_OVERHEAT": {
            "action": "Reduce thermal load and increase cooling",
            "commands": [
                "echo 1 > /sys/class/thermal/cooling_device0/cur_state",
                "systemctl restart fan-controller",
                "cpufreq-set -g powersave",
                "kill -STOP $(pgrep -f non-critical)"
            ],
            "expected_outcome": "CPU temperature should drop below 70C within 5 minutes",
            "risk_level": "low"
        },
        "MEMORY_PRESSURE": {
            "action": "Free memory and restart memory-heavy processes",
            "commands": [
                "sync; echo 3 > /proc/sys/vm/drop_caches",
                "systemctl restart radio_daemon",
                "pkill -9 -f memory_leak_process",
                "swapon -a"
            ],
            "expected_outcome": "Memory usage should drop below 70%",
            "risk_level": "medium"
        },
        "SIGNAL_DEGRADATION": {
            "action": "Optimize antenna and adjust transmission parameters",
            "commands": [
                "radio-cli recalibrate-antenna",
                "radio-cli set-power auto",
                "radio-cli scan-interference",
                "systemctl restart radio_controller"
            ],
            "expected_outcome": "Signal strength should improve by 10-15 dBm",
            "risk_level": "low"
        },
        "BACKHAUL_LATENCY": {
            "action": "Optimize network path and reduce traffic",
            "commands": [
                "tc qdisc replace dev eth0 root fq_codel",
                "ip route flush cache",
                "systemctl restart network-optimizer",
                "ethtool -s eth0 speed 1000 duplex full"
            ],
            "expected_outcome": "Latency should drop below 50ms",
            "risk_level": "low"
        },
        "PROCESS_CRASH": {
            "action": "Restart crashed process and enable core dumps for analysis",
            "commands": [
                "ulimit -c unlimited",
                "systemctl restart radio_controller",
                "journalctl -u radio_controller --since '5 min ago' > /var/log/crash_analysis.log",
                "coredumpctl gdb radio_controller"
            ],
            "expected_outcome": "Process should restart and remain stable",
            "risk_level": "medium"
        },
        "CONFIG_MISMATCH": {
            "action": "Restore configuration from backup and validate",
            "commands": [
                "cp /etc/basestation/radio.conf.backup /etc/basestation/radio.conf",
                "config-validator --check /etc/basestation/radio.conf",
                "systemctl reload radio_controller",
                "logger 'Config restored from backup'"
            ],
            "expected_outcome": "Configuration should be valid and applied",
            "risk_level": "low"
        },
        "POWER_FLUCTUATION": {
            "action": "Activate power protection and reduce load",
            "commands": [
                "power-manager --enable-protection",
                "cpufreq-set -g powersave",
                "radio-cli reduce-power 20",
                "ups-cli --check-battery"
            ],
            "expected_outcome": "System should switch to UPS if needed, power stabilized",
            "risk_level": "high"
        },
        "HIGH_POWER_CONSUMPTION": {
            "action": "Reduce power consumption through efficiency optimization",
            "commands": [
                "radio-cli set-power-mode eco",
                "cpufreq-set -u 1.5GHz",
                "systemctl stop non-essential.target",
                "power-manager --optimize"
            ],
            "expected_outcome": "Power consumption should drop below rated capacity",
            "risk_level": "low"
        },
        "AUTH_FAILURE": {
            "action": "Lock suspicious source and strengthen security",
            "commands": [
                "iptables -A INPUT -s 192.168.1.100 -j DROP",
                "fail2ban-client set sshd banip 192.168.1.100",
                "passwd -l admin",
                "logger -p auth.warning 'Brute force attack detected'"
            ],
            "expected_outcome": "Attack source blocked, accounts secured",
            "risk_level": "low"
        },
        "CERT_EXPIRING": {
            "action": "Renew TLS certificate",
            "commands": [
                "certbot renew --force-renewal",
                "systemctl reload nginx",
                "openssl x509 -in /etc/ssl/certs/server.crt -noout -dates",
                "logger 'Certificate renewed'"
            ],
            "expected_outcome": "Certificate renewed with new expiry date",
            "risk_level": "low"
        }
    }

    def diagnose(self, problem: Problem) -> Solution:
        rule = self.RULES.get(problem.code, {
            "action": "Manual investigation required - unknown problem type",
            "commands": [
                f"logger 'Unknown problem: {problem.code}'",
                "dmesg | tail -100 > /var/log/diagnostic.log",
                "systemctl status --all > /var/log/services.log"
            ],
            "expected_outcome": "Logs collected for manual analysis",
            "risk_level": "unknown"
        })

        return Solution(
            problem_id=problem.id,
            action=rule["action"],
            commands=rule["commands"],
            expected_outcome=rule["expected_outcome"],
            risk_level=rule["risk_level"],
            confidence=0.85 if problem.code in self.RULES else 0.3,
            reasoning=f"Rule-based diagnosis for {problem.code}"
        )

    def is_available(self) -> bool:
        return True


class OllamaBackend(AIBackend):
    """Local Ollama backend for offline AI diagnosis"""

    def __init__(self, model: str = "llama3.2", host: str = "http://localhost:11434"):
        self.model = model
        self.host = host

    def diagnose(self, problem: Problem) -> Solution:
        import requests

        prompt = f"""Diagnose this base station problem and provide a solution:

Problem: {problem.code} - {problem.message}
Metrics: {json.dumps(problem.metrics)}
Logs: {problem.raw_logs}

Respond with JSON: {{"action": "...", "commands": [...], "expected_outcome": "...", "risk_level": "low|medium|high"}}"""

        try:
            response = requests.post(
                f"{self.host}/api/generate",
                json={"model": self.model, "prompt": prompt, "stream": False},
                timeout=60
            )

            if response.ok:
                text = response.json().get("response", "")
                data = json.loads(text)
                return Solution(
                    problem_id=problem.id,
                    action=data.get("action", ""),
                    commands=data.get("commands", []),
                    expected_outcome=data.get("expected_outcome", ""),
                    risk_level=data.get("risk_level", "medium"),
                    confidence=0.7,
                    reasoning="Local LLM analysis"
                )
        except Exception as e:
            logger.error(f"Ollama error: {e}")

        return RuleBasedBackend().diagnose(problem)

    def is_available(self) -> bool:
        try:
            import requests
            r = requests.get(f"{self.host}/api/tags", timeout=2)
            return r.ok
        except Exception:
            return False


# ============================================================================
# Protocol Adapters
# ============================================================================

class ProtocolAdapter(ABC):
    """Base class for communication protocol adapters"""

    def __init__(self, on_problem: Callable[[Problem], Solution]):
        self.on_problem = on_problem
        self.running = False

    @abstractmethod
    def start(self):
        """Start listening for problems"""
        pass

    @abstractmethod
    def stop(self):
        """Stop listening"""
        pass

    @abstractmethod
    def send_solution(self, solution: Solution, destination: Any):
        """Send solution back to device"""
        pass


class TCPAdapter(ProtocolAdapter):
    """TCP/IP Socket adapter for Ethernet communication"""

    def __init__(self, on_problem: Callable, host: str = "0.0.0.0", port: int = 9090):
        super().__init__(on_problem)
        self.host = host
        self.port = port
        self.server = None

    def start(self):
        self.running = True
        self.server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        self.server.bind((self.host, self.port))
        self.server.listen(5)

        logger.info(f"TCP adapter listening on {self.host}:{self.port}")

        def accept_loop():
            while self.running:
                try:
                    self.server.settimeout(1.0)
                    conn, addr = self.server.accept()
                    threading.Thread(target=self._handle_client, args=(conn, addr)).start()
                except socket.timeout:
                    continue
                except Exception as e:
                    if self.running:
                        logger.error(f"TCP accept error: {e}")

        threading.Thread(target=accept_loop, daemon=True).start()

    def _handle_client(self, conn, addr):
        logger.info(f"TCP connection from {addr}")
        try:
            data = b''
            while True:
                chunk = conn.recv(4096)
                if not chunk:
                    break
                data += chunk
                if b'\n' in data:
                    break

            if data:
                problem_data = json.loads(data.decode().strip())
                problem = Problem(**problem_data, source_protocol="tcp")

                solution = self.on_problem(problem)
                self.send_solution(solution, conn)

        except Exception as e:
            logger.error(f"TCP client error: {e}")
        finally:
            conn.close()

    def send_solution(self, solution: Solution, conn: socket.socket):
        try:
            response = json.dumps(asdict(solution)) + '\n'
            conn.sendall(response.encode())
        except Exception as e:
            logger.error(f"Failed to send solution: {e}")

    def stop(self):
        self.running = False
        if self.server:
            self.server.close()


class SerialAdapter(ProtocolAdapter):
    """Serial/UART adapter for RS-232, RS-485, USB Serial"""

    def __init__(self, on_problem: Callable, port: str = "/dev/ttyUSB0",
                 baudrate: int = 115200, timeout: float = 1.0):
        super().__init__(on_problem)
        self.port = port
        self.baudrate = baudrate
        self.timeout = timeout
        self.serial_conn = None

    @staticmethod
    def list_ports() -> List[str]:
        """List available serial ports"""
        if not SERIAL_AVAILABLE:
            return []
        ports = serial.tools.list_ports.comports()
        return [p.device for p in ports]

    def start(self):
        if not SERIAL_AVAILABLE:
            logger.warning("Serial not available - install pyserial")
            return

        self.running = True
        try:
            self.serial_conn = serial.Serial(
                port=self.port,
                baudrate=self.baudrate,
                timeout=self.timeout
            )
            logger.info(f"Serial adapter connected to {self.port} at {self.baudrate} baud")

            def read_loop():
                buffer = ""
                while self.running:
                    try:
                        if self.serial_conn.in_waiting:
                            data = self.serial_conn.read(self.serial_conn.in_waiting).decode()
                            buffer += data

                            while '\n' in buffer:
                                line, buffer = buffer.split('\n', 1)
                                if line.strip():
                                    self._process_message(line.strip())
                    except Exception as e:
                        logger.error(f"Serial read error: {e}")

            threading.Thread(target=read_loop, daemon=True).start()

        except serial.SerialException as e:
            logger.error(f"Failed to open serial port {self.port}: {e}")
            logger.info(f"Available ports: {self.list_ports()}")

    def _process_message(self, message: str):
        try:
            problem_data = json.loads(message)
            problem = Problem(**problem_data, source_protocol="serial")
            solution = self.on_problem(problem)
            self.send_solution(solution, None)
        except json.JSONDecodeError:
            logger.warning(f"Invalid JSON from serial: {message[:100]}")

    def send_solution(self, solution: Solution, _):
        if self.serial_conn and self.serial_conn.is_open:
            response = json.dumps(asdict(solution)) + '\n'
            self.serial_conn.write(response.encode())

    def stop(self):
        self.running = False
        if self.serial_conn:
            self.serial_conn.close()


class MQTTAdapter(ProtocolAdapter):
    """MQTT adapter for IoT communication"""

    def __init__(self, on_problem: Callable, broker: str = "localhost", port: int = 1883,
                 topic_problems: str = "basestation/+/problems",
                 topic_solutions: str = "basestation/{station_id}/solutions"):
        super().__init__(on_problem)
        self.broker = broker
        self.port = port
        self.topic_problems = topic_problems
        self.topic_solutions = topic_solutions
        self.client = None

    def start(self):
        if not MQTT_AVAILABLE:
            logger.warning("MQTT not available - install paho-mqtt")
            return

        self.running = True
        self.client = mqtt.Client()

        def on_connect(client, userdata, flags, rc):
            logger.info(f"MQTT connected to {self.broker}:{self.port}")
            client.subscribe(self.topic_problems)

        def on_message(client, userdata, msg):
            try:
                problem_data = json.loads(msg.payload.decode())
                problem = Problem(**problem_data, source_protocol="mqtt")
                solution = self.on_problem(problem)
                self.send_solution(solution, problem.station_id)
            except Exception as e:
                logger.error(f"MQTT message error: {e}")

        self.client.on_connect = on_connect
        self.client.on_message = on_message

        try:
            self.client.connect(self.broker, self.port)
            self.client.loop_start()
        except Exception as e:
            logger.error(f"MQTT connection failed: {e}")

    def send_solution(self, solution: Solution, station_id: str):
        if self.client:
            topic = self.topic_solutions.format(station_id=station_id)
            self.client.publish(topic, json.dumps(asdict(solution)))

    def stop(self):
        self.running = False
        if self.client:
            self.client.loop_stop()
            self.client.disconnect()


class HTTPAdapter(ProtocolAdapter):
    """HTTP/REST API adapter with HMAC authentication and OpenTelemetry tracing"""

    def __init__(self, on_problem: Callable, host: str = "0.0.0.0", port: int = 9091):
        super().__init__(on_problem)
        self.host = host
        self.port = port
        self.app = None
        self.secret = os.environ.get("DIAGNOSTIC_SECRET", "")
        self.tracer = None
        # References to diagnostic logs and learning engine (set by DiagnosticService)
        self.problem_log: List[Problem] = []
        self.solution_log: List[Solution] = []
        self.learning_engine: Optional[LearningEngine] = None
        self.diagnostic_service = None  # Reference to parent service for feedback
        require_auth = os.environ.get("DIAGNOSTIC_REQUIRE_AUTH", "false").lower() == "true"
        if not self.secret:
            if require_auth:
                raise ValueError("DIAGNOSTIC_SECRET is required when DIAGNOSTIC_REQUIRE_AUTH=true")
            logger.warning("DIAGNOSTIC_SECRET not set - authentication disabled (set DIAGNOSTIC_REQUIRE_AUTH=true in production)")

    def _setup_tracing(self):
        """Initialize OpenTelemetry tracing"""
        if not OTEL_AVAILABLE:
            logger.info("OpenTelemetry not available - tracing disabled")
            return

        zipkin_endpoint = os.environ.get("ZIPKIN_ENDPOINT", "http://zipkin:9411/api/v2/spans")

        try:
            resource = Resource.create({"service.name": "ai-diagnostic"})
            provider = TracerProvider(resource=resource)
            exporter = ZipkinExporter(endpoint=zipkin_endpoint)
            provider.add_span_processor(BatchSpanProcessor(exporter))
            trace.set_tracer_provider(provider)
            self.tracer = trace.get_tracer(__name__)

            # Instrument Flask app
            if self.app:
                FlaskInstrumentor().instrument_app(self.app)

            logger.info(f"OpenTelemetry tracing enabled, exporting to {zipkin_endpoint}")
        except Exception as e:
            logger.warning(f"Failed to initialize tracing: {e}")

    def _verify_hmac(self, body: bytes, signature: str) -> bool:
        """Verify HMAC signature of request body"""
        if not self.secret:
            return True  # Auth disabled if no secret configured

        expected = hmac.new(
            self.secret.encode(),
            body,
            hashlib.sha256
        ).hexdigest()

        return hmac.compare_digest(expected, signature)

    def _require_auth(self, f):
        """Decorator to require HMAC authentication"""
        @wraps(f)
        def decorated(*args, **kwargs):
            if not self.secret:
                return f(*args, **kwargs)

            signature = request.headers.get("X-HMAC-Signature", "")
            if not signature:
                logger.warning("Missing X-HMAC-Signature header")
                return jsonify({"error": "Missing authentication"}), 401

            if not self._verify_hmac(request.get_data(), signature):
                logger.warning("Invalid HMAC signature from %s", request.remote_addr)
                return jsonify({"error": "Invalid authentication"}), 403

            return f(*args, **kwargs)
        return decorated

    def start(self):
        if not FLASK_AVAILABLE:
            logger.warning("Flask not available - install flask")
            return

        self.running = True
        self.app = Flask(__name__)

        # Enable CORS for browser requests
        @self.app.after_request
        def add_cors_headers(response):
            response.headers['Access-Control-Allow-Origin'] = '*'
            response.headers['Access-Control-Allow-Methods'] = 'GET, POST, OPTIONS'
            response.headers['Access-Control-Allow-Headers'] = 'Content-Type, X-HMAC-Signature'
            return response

        # Setup OpenTelemetry tracing
        self._setup_tracing()

        @self.app.route('/diagnose', methods=['POST'])
        @self._require_auth
        def diagnose():
            problem_data = request.json
            problem = Problem(**problem_data, source_protocol="http")
            solution = self.on_problem(problem)
            return jsonify(asdict(solution))

        @self.app.route('/health', methods=['GET'])
        def health():
            return jsonify({
                "status": "ok",
                "authenticated": bool(self.secret),
                "tracing": OTEL_AVAILABLE and self.tracer is not None
            })

        @self.app.route('/reports/bi', methods=['GET'])
        def generate_bi_report():
            """Generate BI report PDF on-demand"""
            if not BI_REPORT_AVAILABLE:
                return jsonify({"error": "BI report generation not available"}), 503

            api_url = os.environ.get("API_GATEWAY_URL", "http://localhost:8080")
            generator = BIReportGenerator(api_url)
            pdf_bytes = generator.generate_report_bytes()

            if pdf_bytes is None:
                return jsonify({"error": "Failed to generate report"}), 500

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"bi-report-{timestamp}.pdf"

            return Response(
                pdf_bytes,
                mimetype='application/pdf',
                headers={
                    'Content-Disposition': f'attachment; filename="{filename}"',
                    'Content-Length': str(len(pdf_bytes))
                }
            )

        @self.app.route('/reports/diagnostics', methods=['GET'])
        def get_diagnostics_log():
            """Return AI diagnostics problem and solution logs"""
            diagnostics = []

            # Pair problems with their solutions
            for i, problem in enumerate(self.problem_log):
                entry = {
                    "id": problem.id,
                    "timestamp": problem.timestamp,
                    "station_id": problem.station_id,
                    "category": problem.category,
                    "severity": problem.severity,
                    "code": problem.code,
                    "message": problem.message,
                    "source_protocol": problem.source_protocol,
                    "solution": None
                }

                # Find matching solution
                if i < len(self.solution_log):
                    sol = self.solution_log[i]
                    entry["solution"] = {
                        "action": sol.action,
                        "commands": sol.commands,
                        "expected_outcome": sol.expected_outcome,
                        "risk_level": sol.risk_level,
                        "confidence": sol.confidence,
                        "reasoning": sol.reasoning
                    }

                diagnostics.append(entry)

            return jsonify({
                "total": len(diagnostics),
                "diagnostics": diagnostics
            })

        @self.app.route('/learning/feedback', methods=['POST'])
        @self._require_auth
        def submit_feedback():
            """Submit feedback on a diagnostic solution for learning."""
            if not self.diagnostic_service:
                return jsonify({"error": LEARNING_ENGINE_NOT_AVAILABLE}), 503

            data = request.json
            problem_code = data.get('problem_code')
            category = data.get('category', 'unknown')
            was_effective = data.get('was_effective', False)
            action = data.get('action', '')

            if not problem_code:
                return jsonify({"error": "problem_code is required"}), 400

            pattern = self.diagnostic_service.record_feedback(
                problem_code, category, was_effective, action
            )

            return jsonify({
                "problem_code": pattern.problem_code,
                "success_rate": pattern.success_rate(),
                "resolved_count": pattern.resolved_count,
                "failed_count": pattern.failed_count,
                "adjusted_confidence": pattern.adjusted_confidence
            })

        @self.app.route('/learning/stats', methods=['GET'])
        def get_learning_stats():
            """Get learning statistics."""
            if not self.learning_engine:
                return jsonify({"error": LEARNING_ENGINE_NOT_AVAILABLE}), 503
            return jsonify(self.learning_engine.get_stats())

        @self.app.route('/learning/patterns', methods=['GET'])
        def get_patterns():
            """Get all learned patterns."""
            if not self.learning_engine:
                return jsonify({"error": LEARNING_ENGINE_NOT_AVAILABLE}), 503

            patterns = self.learning_engine.get_all_patterns()
            return jsonify({
                "total": len(patterns),
                "patterns": [
                    {
                        "problem_code": p.problem_code,
                        "category": p.category,
                        "resolved_count": p.resolved_count,
                        "failed_count": p.failed_count,
                        "success_rate": p.success_rate(),
                        "adjusted_confidence": p.adjusted_confidence,
                        "successful_actions": p.successful_actions,
                        "failed_actions": p.failed_actions
                    }
                    for p in patterns
                ]
            })

        @self.app.route('/learning/patterns/<problem_code>', methods=['GET'])
        def get_pattern(problem_code):
            """Get a specific learned pattern."""
            if not self.learning_engine:
                return jsonify({"error": LEARNING_ENGINE_NOT_AVAILABLE}), 503

            pattern = self.learning_engine.get_pattern(problem_code)
            if not pattern:
                return jsonify({"error": "Pattern not found"}), 404

            return jsonify({
                "problem_code": pattern.problem_code,
                "category": pattern.category,
                "resolved_count": pattern.resolved_count,
                "failed_count": pattern.failed_count,
                "success_rate": pattern.success_rate(),
                "adjusted_confidence": pattern.adjusted_confidence,
                "successful_actions": pattern.successful_actions,
                "failed_actions": pattern.failed_actions
            })

        threading.Thread(
            target=lambda: self.app.run(host=self.host, port=self.port, threaded=True),
            daemon=True
        ).start()

        logger.info(f"HTTP adapter listening on {self.host}:{self.port}")

    def send_solution(self, solution: Solution, _):
        pass  # HTTP is request/response, solution sent in response

    def stop(self):
        self.running = False


# ============================================================================
# Main Diagnostic Service
# ============================================================================

class DiagnosticService:
    """
    Main AI Diagnostic Service

    Manages multiple protocol adapters, AI backends, and the learning engine.
    """

    def __init__(self):
        self.adapters: List[ProtocolAdapter] = []
        self.backend: AIBackend = RuleBasedBackend()
        self.problem_log: List[Problem] = []
        self.solution_log: List[Solution] = []
        self.learning_engine = LearningEngine()

    def set_backend(self, backend: AIBackend):
        """Set the AI backend for diagnosis"""
        self.backend = backend
        logger.info(f"AI backend set to: {type(backend).__name__}")

    def add_adapter(self, adapter: ProtocolAdapter):
        """Add a protocol adapter"""
        self.adapters.append(adapter)
        logger.info(f"Added adapter: {type(adapter).__name__}")

    def record_feedback(self, problem_code: str, category: str,
                        was_effective: bool, action: str) -> LearnedPattern:
        """Record operator feedback and update learning patterns."""
        pattern = self.learning_engine.update_pattern(
            problem_code, category, was_effective, action
        )
        logger.info(f"Feedback recorded for {problem_code}: "
                   f"effective={was_effective}, success_rate={pattern.success_rate():.1f}%")
        return pattern

    def _handle_problem(self, problem: Problem) -> Solution:
        """Central problem handler called by all adapters"""
        logger.info(f"Received problem from {problem.source_protocol}: "
                   f"[{problem.severity}] {problem.code}")

        self.problem_log.append(problem)

        # Diagnose using AI backend
        solution = self.backend.diagnose(problem)

        # Adjust confidence based on learned patterns
        adjusted_confidence = self.learning_engine.get_adjusted_confidence(
            problem.code, solution.confidence
        )
        if adjusted_confidence != solution.confidence:
            logger.info(f"Adjusted confidence for {problem.code}: "
                       f"{solution.confidence:.0%} -> {adjusted_confidence:.0%}")
            solution.confidence = adjusted_confidence

        self.solution_log.append(solution)

        logger.info(f"Generated solution: {solution.action} "
                   f"(confidence: {solution.confidence:.0%})")

        return solution

    def start(self):
        """Start all adapters"""
        logger.info("Starting AI Diagnostic Service")
        logger.info(f"Backend: {type(self.backend).__name__}")
        logger.info(f"Adapters: {len(self.adapters)}")
        logger.info("Learning Engine: enabled")

        for adapter in self.adapters:
            adapter.on_problem = self._handle_problem
            # Share log and learning references with HTTPAdapter
            if isinstance(adapter, HTTPAdapter):
                adapter.problem_log = self.problem_log
                adapter.solution_log = self.solution_log
                adapter.learning_engine = self.learning_engine
                adapter.diagnostic_service = self
            adapter.start()

    def stop(self):
        """Stop all adapters"""
        for adapter in self.adapters:
            adapter.stop()
        logger.info("Diagnostic service stopped")


def main():
    import argparse

    parser = argparse.ArgumentParser(description="AI Diagnostic Service")
    parser.add_argument("--tcp-port", type=int, default=9090, help="TCP port")
    parser.add_argument("--http-port", type=int, default=9091, help="HTTP port")
    parser.add_argument("--serial", help="Serial port (e.g., /dev/ttyUSB0)")
    parser.add_argument("--mqtt-broker", help="MQTT broker address")
    parser.add_argument("--backend", choices=["rules", "ollama"],
                       default="rules", help="AI backend")
    parser.add_argument("--ollama-model", default="llama3.2", help="Ollama model")

    args = parser.parse_args()

    service = DiagnosticService()

    # Set AI backend
    if args.backend == "ollama":
        service.set_backend(OllamaBackend(model=args.ollama_model))
    else:
        service.set_backend(RuleBasedBackend())

    # Add protocol adapters
    service.add_adapter(TCPAdapter(None, port=args.tcp_port))

    if FLASK_AVAILABLE:
        service.add_adapter(HTTPAdapter(None, port=args.http_port))

    if args.serial:
        service.add_adapter(SerialAdapter(None, port=args.serial))

    if args.mqtt_broker and MQTT_AVAILABLE:
        service.add_adapter(MQTTAdapter(None, broker=args.mqtt_broker))

    service.start()

    logger.info("\n" + "="*60)
    logger.info("AI Diagnostic Service is running")
    logger.info("="*60)
    logger.info(f"  TCP:  localhost:{args.tcp_port}")
    if FLASK_AVAILABLE:
        logger.info(f"  HTTP: http://localhost:{args.http_port}/diagnose")
    if args.serial:
        logger.info(f"  Serial: {args.serial}")
    if args.mqtt_broker:
        logger.info(f"  MQTT: {args.mqtt_broker}")
    logger.info("="*60 + "\n")

    try:
        while True:
            import time
            time.sleep(1)
    except KeyboardInterrupt:
        service.stop()


if __name__ == "__main__":
    main()
